# VRInteractionToolkit

# Check out our current Wiki-Page
https://github.com/WearableComputerLab/VRInteractionToolkit/wiki

# Experimental user-testing notes
https://docs.google.com/document/d/1k7izoVzxvIplMprO6Qyx0WdaG2XJE-3ktmCyfQcRUh4/edit?usp=sharing

# List of Techniques (Updated Weekly)
https://docs.google.com/document/d/1z1cqlON__YbIfm96woaRHOlqhPY0gTIAuAptGbjNyoI

# Full Systems Requirement document available at:
https://docs.google.com/document/d/1FSQwYgCCjmWu63tQH6qZWRbKkr2_fT3JTO9mafTVEZs

Project Scope

To implement (and re-implement) the specified virtual reality user interaction techniques by the client as an open-source alternative to make them more accessible to the community. These techniques will be created as individual prefabs within the Unity video game engine so that they can be dropped onto an existing project to be utilized easily by anyone. They must be cross-platform and work with any primarily the HTC Vive and Oculus VR hardware that utilizes VR goggles, motion controllers, and tracking sensors. The techniques must be highly customizable while still easy to use. 
The end product will contain all of these techniques with the ability to be imported individually to unity as well as a ‘Test environment’ which would allow the user to enter an in-game space where they can select different techniques and try them out all at once. This product will be uploaded publicly to github (with concise descriptions and tutorials on how the interaction techniques work) as well as the unity asset store for anybody to use. 
As a bonus If the above has been completed within the time constraints with excess time to spare spatial movement techniques will be researched and implemented within the test environment.

The techniques we'll be implementing are divided into 6 different categories classified by their metaphors:
Grasping - Techniques which involve the user grasping and manipulation objects with their virtual hands.
Pointing - Techniques which involve the user selecting and manipulating objects beyond the area of the users reach by pointing at them.
Surface - Techniques which involve the user using touch gestures to directly interact with virtual objects.
Indirect - Techniques which involves the user to manipulate virtual objects without directly interacting with them.
Bimanual - Techniques which involves the user using both hands to manipulate or interact with virtual objects.
Hybrid - Techniques which involves combing different interaction and manipulation techniques.


#Reference
All techniques implemented in this project are based off the research of other people, and have been acquired from the textbook '3D User Interfaces theory and practice'
Full reference below:
LaViola, J., Kruijff, E., McMahan, R., Bowman, D. and Poupyrev, I. (2017). 3D user interfaces. 2nd ed. Boston: Addison-Wesley, pp.256-315.
